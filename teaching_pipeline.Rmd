---
title: "Teaching Pipeline"
author: "Lukas Dreyling & Henrique Valim"
date: "2022-09-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r klippy, echo=FALSE, include=TRUE}
library(klippy)
klippy::klippy()
```

## Program List 

 * guppy (will run internally?)
    + already demultiplexes and filters low quality reads
 * Decona pipeline
    + CD-Hit &rarr; clustering Reads 
    + Minimap2 &rarr; align reads
    + Racon &rarr; make consensus sequences
    + Medaka &rarr; plosih the sequences
 * Blast+
 * R (and RStudio)
    + packages: vegan, microbiome, ggplot, here 
    
## Basecalling and Demultiplexing 

### Guppy 

```{bash, eval = F}
#!/bin/bash

#SBATCH -n 4
#SBATCH -p gpu
#SBATCH -t 12:00:00
#SBATCH -J guppy_gpu
#SBATCH -o guppy_gpu.o%j
#SBATCH -e guppy_gpu.e%j

module load guppy

cd $SLURM_SUBMIT_DIR

guppy_basecaller -i fast5_pass -s fastq_9.4_pass -c dna_r9.4.1_450bps_hac.cfg -x "cuda:1" --barcode_kits SQK-RBK001
guppy_basecaller -i fast5_skip -s fastq_9.4_skip -c dna_r9.4.1_450bps_hac.cfg -x "cuda:1" --barcode_kits SQK-RBK001

scontrol show job $SLURM_JOB_ID

```

- barcode removal is on by default if using the demultiplexing flag (--barcode_kits)

# Turn Fastq to Fasta

### We want to create a folder where we can store the FASTA files and need to unzip the FASTQ files. 

```{bash}
mkdir ./fasta_pass

cd fastq_pass 

gzip -d fastq_pass/*.gz

cd .. 
```


 * later we need the reads in fasta format so we need to convert 
```{bash}
# enter the folder where the .fastq files are stored.
cd fastq_pass

# Turn all .fastq files inside the folder into .fasta files
for i in *.fastq ;  do
            if [ -e "$i" ] ; then
            cat "$i" | grep -A 1 'runid' | sed '/^--$/d' | sed 's/^@/>/' | awk '{print $1}' > "${i%%.*}.fasta" ; 
            fi
            done

# Move the .fasta files to the folder we created before.
mv ./*.fasta ../fasta_pass

# Exit the fastq_pass folder 
cd .. 
```

## Clustering the Reads

 * to obtain groups of similar reads 
 * potentially the same species/OTU
 * CD-Hit
 * combine all reads from one barcode in one big fasta to get accurate clusters
 
```{bash}
# Enter the folder where we stored the .fasta files
cd fasta_pass

# Combine all fasta files into one big one per sample. 
cat *.fasta > full_sequences.fa

# Clustering reads to make a list of most abundant, representative reads
    for fasta in *.fa ; do
    if [ -e "$fasta" ] ; then
    # This is the actual clustering command
    cd-hit-est -i "$fasta" -o cluster_representatives${fasta%.*} -c 0.95 -n 8 -d 0 -M 0 -T 0 -g 1 > report_"${fasta%.*}.txt"; 
    fi
    done

# Have a look at the cluster sizes
for clstr in *.clstr ; do
    if [ -e "$clstr" ] ; then
    # Read distribution will be summarized in report_***.txt within the folder.
    plot_len1.pl "$clstr" \
    1,2-4,5-9,10-19,20-49,50-99,100-299,300-499,500-999 \
    10-59,60-149,150-499,500-1999,2000-999999 \
    >> size_report_"$clstr".txt ;
    fi
    done
    
    
# Create files with clusters of a certain size
 make_multi_seq.pl *.fa *.clstr multi-seq 2 

```

## Align clustered Reads

```{bash}
# Align with minimap2 and assemble with Racon

# Navigate to the folder with our cluster sequences
cd multi-seq

# Add .fa to all filenames...unless they are already .fa
for file in *; do 
case "$file" in *.fa) echo skipped $file;; *) mv "$file" "$file".fa; esac; done


    for file in *.fa ;  do
        if [ -e "${file}" ] ; then
        echo "Aligning and making draft assembly of $file...";
        # Extract 1st sequence of each file as a reference point
        tail -n 2 "${file}" > ref_"${file}"sta;
        # Aligning all data in the cluster to the reference sequence
        minimap2 -ax map-ont ref_"${file}"sta "${file}" -t 3 > align_"${file}".sam ;

        #Assemble the clustered sequences.
        # Racon settings optimized for Medaka: -m 8 -x -6 -g -8 -w 500
        racon -m 8 -x -6 -g -8 -w 500 -t 3 "${file}" align_"${file}".sam ref_"${file}"sta > polished_"${file}"sta ;
        fi
        done
        
        
# Extract 1st sequence of each file as a reference point
        tail -n 2 "${file}" > ref_"${file}"sta;
        # Aligning all data in the cluster to the reference sequence
        minimap2 -ax map-ont ref_"${file}"sta "${file}" -t 3 > align_"${file}".sam ;

        #Assemble the clustered sequences.
        # Racon settings optimized for Medaka: -m 8 -x -6 -g -8 -w 500
        racon -m 8 -x -6 -g -8 -w 500 -t 3 "${file}" align_"${file}".sam ref_"${file}"sta > polished_"${file}"sta
```

## Polishing with Medaka

```{bash}
if [ $MEDAKA == "yes" ] ; then
    #Polish the Racon secuence with Medaka
    for folder in */ ; do
    if [ -e "$folder"/multi-seq ] ; then
    (
    cd "$folder"/"multi-seq" || exit ;
        for fa in *.fa ;  do
        if [ -e "polished_${fa}sta" ] ; then
        echo "polishing ${fa} Racon sequence with Medaka..."
        medaka_consensus -i "${fa}" -d "polished_${fa}sta" -o "consensus_medaka_${fa}" -t "$MULTITHREAD" ;
        fi
        done
    echo "Done polishing ${fa}";
    )
    fi
    done

    #Change names of Medaka consensus to have their cluster's name
    #move them one folder up
    for folder in */ ; do
    if [ -e "${folder}"/multi-seq ] ; then
    (
    cd "${folder}"/"multi-seq" || exit ;
    for folders in consensus_medaka_*; do
    if [ -e "${folders}" ] ; then
    (
        cd "${folders}" || exit ;
        [ ! -f consensus.fasta ] || mv consensus.fasta "${folders}sta"
        [ ! -f "${folders}sta" ] || mv "${folders}sta" ..
    )
    fi
    done
    )
    fi
    done
```

## Blast search against UNITE database

```{bash}

```

